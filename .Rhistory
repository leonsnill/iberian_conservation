df_cl <- df_cl[-c(1),]
df <- data.frame(t(raster::extract(img_probs, points, df=T)))
df <- df[-c(1),]
df$year <- 1985:2019
# Point 1: Olive until 1999, then glasshouse infrastructure (very clear): 1->2
z1 <- c(rep(1, 14), rep(2, 21))
P1 <- data.frame(year = 1985:2019, x = df$X1, z = z1, z_rf = df_cl$C1)
# Point 2: Meditteranean shrubland
z2 <- rep(2, 35)
P2 <- data.frame(year = 1985:2019, x = df$X2, z = z2, z_rf = df_cl$C2)
# Point 3: Constant Olives (large fluctauations in predictions)
z3 <- rep(1, 35)
P3 <- data.frame(year = 1985:2019, x = df$X3, z = z3, z_rf = df_cl$C3)
# Point 4: Constant Olive with (false) outliers to non-olive
z4 <- rep(1, 35)
P4 <- data.frame(year = 1985:2019, x = df$X4, z = z4, z_rf = df_cl$C4)
# Point 4: Olive until 2001, then glasshouse infrastructure (not so clear)
z5 <- c(rep(1, 17), rep(2, 18))
P5 <- data.frame(year = 1985:2019, x = df$X5, z = z5, z_rf = df_cl$C5)
library(ggplot2)
plt1 <- ggplot(data=P1) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="red") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
plt2 <- ggplot(data=P2) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="green") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
plt4 <- ggplot(data=P4) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="blue") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
plt5 <- ggplot(data=P5) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="black") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
library(gridExtra)
grid.arrange(plt1, plt2, plt4, plt5)
library(rstan)
fit_hmm <- function(K, y) {
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
stan.model = 'C:/Users/Leon/Google Drive/03_LSNRS/Code/03_git/hmm_stan/stan/hmm_gaussian_leon.stan'
stan.data = list(
T = length(y),              # length of the sequence
K = K,                      # number of states
y=y,                        # observations / signal
mu_alpha = c(1.5, 3),       # prior alpha param. of beta dist. of observation model's mu
mu_beta = c(3, 1.5),        # prior beta param. of beta dist. of observation model's mu
sigma_prior = c(2, 2),
alpha_prior1 = c(0.7, 0.3), # prior transition probabilities for Dirichlet distribution (state 1)
alpha_prior2 = c(0.3, 0.7)  # # prior transition probabilities for Dirichlet distribution (state 2)
)
stan(file = stan.model,
data = stan.data, verbose = T, iter = 2000, warmup = 500,
thin = 1, chains = 4,
cores = 4, seed = 30,
init = function(){list(mu = c(0.1, 0.9), sigma = c(0.3, 0.3), pi1 = c(0.5, 0.5))})  # initialization values for the observational models params. Especially needed for one-state trajectories to label state's correctly
}
K <- 2 # number of states
p1_fit <- fit_hmm(K, P1$x)
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/Leon/Google Drive/01_MSc_GCG/MSc_ASM/MAP")
library(raster)
library(rgdal)
library(tidyverse)
# read imagery and reference points
img_probs <- raster::brick("C:/Users/Leon/Google Drive/04_Geomatik/00_projects/KRITI/data/stacked.tif")/10000
img_cl <- raster::brick("C:/Users/Leon/Google Drive/04_Geomatik/00_projects/KRITI/data/stacked_MLP.tif")
img_cl <- img_cl+1
img_cl[img_cl == 3] <- 1
points <- readOGR("C:/Users/Leon/Google Drive/01_MSc_GCG/MSc_ASM/MAP/rf_prob_example.gpkg")
plot(img_probs[[1]])
plot(points, pch=13, cex=2, add=T)
# extract observations at point locations
df_cl <- data.frame(t(raster::extract(img_cl, points, df=T)))
names(df_cl) <- c("C1", "C2", "C3", "C4", "C5")
df_cl <- df_cl[-c(1),]
df <- data.frame(t(raster::extract(img_probs, points, df=T)))
df <- df[-c(1),]
df$year <- 1985:2019
# Point 1: Olive until 1999, then glasshouse infrastructure (very clear): 1->2
z1 <- c(rep(1, 14), rep(2, 21))
P1 <- data.frame(year = 1985:2019, x = df$X1, z = z1, z_rf = df_cl$C1)
# Point 2: Meditteranean shrubland
z2 <- rep(2, 35)
P2 <- data.frame(year = 1985:2019, x = df$X2, z = z2, z_rf = df_cl$C2)
# Point 3: Constant Olives (large fluctauations in predictions)
z3 <- rep(1, 35)
P3 <- data.frame(year = 1985:2019, x = df$X3, z = z3, z_rf = df_cl$C3)
# Point 4: Constant Olive with (false) outliers to non-olive
z4 <- rep(1, 35)
P4 <- data.frame(year = 1985:2019, x = df$X4, z = z4, z_rf = df_cl$C4)
# Point 4: Olive until 2001, then glasshouse infrastructure (not so clear)
z5 <- c(rep(1, 17), rep(2, 18))
P5 <- data.frame(year = 1985:2019, x = df$X5, z = z5, z_rf = df_cl$C5)
library(ggplot2)
plt1 <- ggplot(data=P1) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="red") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
plt2 <- ggplot(data=P2) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="green") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
plt4 <- ggplot(data=P4) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="blue") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
plt5 <- ggplot(data=P5) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="black") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
library(gridExtra)
grid.arrange(plt1, plt2, plt4, plt5)
df
# Point 1: Olive until 1999, then glasshouse infrastructure (very clear): 1->2
z1 <- c(rep(1, 14), rep(2, 21))
P1 <- data.frame(year = 1985:2019, x = df$X1, z = z1, z_rf = df_cl$C1)
# Point 2: Meditteranean shrubland
z2 <- rep(2, 35)
P2 <- data.frame(year = 1985:2019, x = df$X2, z = z2, z_rf = df_cl$C2)
# Point 3: Constant Olives (large fluctauations in predictions)
z3 <- rep(1, 35)
P3 <- data.frame(year = 1985:2019, x = df$X3, z = z3, z_rf = df_cl$C3)
# Point 4: Constant Olive with (false) outliers to non-olive
z4 <- rep(1, 35)
P4 <- data.frame(year = 1985:2019, x = df$X4, z = z4, z_rf = df_cl$C4)
# Point 4: Olive until 2001, then glasshouse infrastructure (not so clear)
z5 <- c(rep(1, 17), rep(2, 18))
P5 <- data.frame(year = 1985:2019, x = df$X5, z = z5, z_rf = df_cl$C5)
P1
P1
write.csv(P1, "C:\\Users\\Leon\\PycharmProjects\\eolab\\Olive\\HMM\\data\\p1.csv")
P4
write.csv(P4, "C:\\Users\\Leon\\PycharmProjects\\eolab\\Olive\\HMM\\data\\p4.csv")
library(raster)
library(rgdal)
library(tidyverse)
# read imagery and reference points
img_probs <- raster::brick("C:/Users/Leon/Google Drive/04_Geomatik/00_projects/KRITI/data/stacked.tif")/10000
img_cl <- raster::brick("C:/Users/Leon/Google Drive/04_Geomatik/00_projects/KRITI/data/stacked_MLP.tif")
img_cl <- img_cl+1
img_cl[img_cl == 3] <- 1
points <- readOGR("C:/Users/Leon/Google Drive/01_MSc_GCG/MSc_ASM/MAP/rf_prob_example.gpkg")
plot(img_probs[[1]])
plot(points, pch=13, cex=2, add=T)
# extract observations at point locations
df_cl <- data.frame(t(raster::extract(img_cl, points, df=T)))
names(df_cl) <- c("C1", "C2", "C3", "C4", "C5")
df_cl <- df_cl[-c(1),]
df <- data.frame(t(raster::extract(img_probs, points, df=T)))
df <- df[-c(1),]
df$year <- 1985:2019
# Point 1: Olive until 1999, then glasshouse infrastructure (very clear): 1->2
z1 <- c(rep(1, 14), rep(2, 21))
P1 <- data.frame(year = 1985:2019, x = df$X1, z = z1, z_rf = df_cl$C1)
# Point 2: Meditteranean shrubland
z2 <- rep(2, 35)
P2 <- data.frame(year = 1985:2019, x = df$X2, z = z2, z_rf = df_cl$C2)
# Point 3: Constant Olives (large fluctauations in predictions)
z3 <- rep(1, 35)
P3 <- data.frame(year = 1985:2019, x = df$X3, z = z3, z_rf = df_cl$C3)
# Point 4: Constant Olive with (false) outliers to non-olive
z4 <- rep(1, 35)
P4 <- data.frame(year = 1985:2019, x = df$X4, z = z4, z_rf = df_cl$C4)
# Point 4: Olive until 2001, then glasshouse infrastructure (not so clear)
z5 <- c(rep(1, 17), rep(2, 18))
P5 <- data.frame(year = 1985:2019, x = df$X5, z = z5, z_rf = df_cl$C5)
library(ggplot2)
plt1 <- ggplot(data=P1) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="red") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
plt2 <- ggplot(data=P2) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="green") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
plt4 <- ggplot(data=P4) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="blue") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
plt5 <- ggplot(data=P5) + geom_hline(yintercept=0.5) + ylab("Non-Olive Prob.") + xlab("Year") +
geom_point(aes(x = year, y = x), color="black") + ylim(0, 1) +
geom_line(aes(x = year, y = z-1), size=3, color="lightpink", alpha=0.8) +  theme_bw() +
geom_line(aes(x = year, y = z_rf-1), color="red")
library(gridExtra)
grid.arrange(plt1, plt2, plt4, plt5)
write.csv(P5, "C:\\Users\\Leon\\PycharmProjects\\eolab\\Olive\\HMM\\data\\p5.csv")
write.csv(P2, "C:\\Users\\Leon\\PycharmProjects\\eolab\\Olive\\HMM\\data\\p2.csv")
write.csv(P3, "C:\\Users\\Leon\\PycharmProjects\\eolab\\Olive\\HMM\\data\\p3.csv")
library(raster)
library(dplyr)
library(tidyverse)
library(corrplot)
library(ecospat)
library(mecofun)
mecofun::select07_cv()
wd <- "C:/Users/Leon/Google Drive/03_LSNRS/Projects/Iberian_Conservation/iberian_conservation"
setwd(wd)
species <- "ursusarctos"
# ----------------------------------------------------------------------------------------------------
# FUNCTIONS
# ----------------------------------------------------------------------------------------------------
# AUTOMATED PREDICTIONS (altered for weighted predictions)
make.preds <- function(model, newdata) {
require(dismo)
require(gam)
require(rpart)
require(randomForest)
require(gbm)
require(maxnet)
require(kernlab)
switch(class(model)[1],
Bioclim = predict(model, newdata),
Domain = predict(model, newdata),
glm = predict(model, newdata, type='response', weights = weight),
Gam = predict(model, newdata, type='response', weights = weight),
rpart = predict(model, newdata),
randomForest = predict(model, newdata, type='prob', na.action = na.omit)[,2],
gbm = predict.gbm(model, newdata,
n.trees=model$gbm.call$best.trees, type="response"),
maxnet = predict(model, newdata, type="logistic"),
gausspr = predict(model, newdata, type="probabilities"))
}
# K-FOLD CROSSVALIDATION
crossval.preds <- function(model, X_train, y_name, x_name,
X_raster, colname_coord, kfold) {
require(dismo)
require(gam)
require(rpart)
require(randomForest)
require(gbm)
require(maxnet)
require(kernlab)
# Make k-fold data partitions
ks <- kfold(X_train, k = kfold, by = X_train[,y_name])
cross_val_preds <- data.frame(row = row.names(X_train),
cross_val_preds = numeric(length = nrow(X_train)))
for (i in seq_len(kfold)) {
cv_train <- X_train[ks != i,]
cv_test <- X_train[ks == i,]
# force equal presence-absence for ML algorithms
if (class(model)[1]=='randomForest' | class(model)[1]=='rpart' | class(model)[1]=='gbm' | class(model)[1]=='gausspr') {
n_pre_cv <- dim(cv_train[cv_train$species == 1,])[1]
cv_train_abs <- sample_n(cv_train[cv_train$species == 0,], n_pre_cv)
cv_train <- rbind(cv_train_abs, cv_train[cv_train$species == 1,])
}
# Because we used the gbm.step() for BRTs, we need a small work-around:
if (class(model)[1]=='gbm') {
cv_train_gbm <- cv_train;
names(cv_train_gbm)[names(cv_train_gbm)==y_name] <-
model$response.name
}
# We update the model for the new training data
modtmp <- switch(class(model)[1],
Bioclim = bioclim(X_raster[[x_name]], cv_train[cv_train[, y_name]==1, colname_coord]),
Domain = domain(X_raster[[x_name]], cv_train[cv_train[, y_name]==1, colname_coord]),
glm = update(model, data=cv_train, weights = weight),
Gam = update(model, data=cv_train, weights = weight),
rpart = update(model, data=cv_train),
randomForest = update(model, data=cv_train),
gbm = gbm(model$call, 'bernoulli', data=cv_train_gbm[,c(x_name,model$response.name)], n.trees=model$gbm.call$best.trees, shrinkage=model$gbm.call$learning.rate, bag.fraction=model$gbm.call$bag.fraction, interaction.depth=model$gbm.call$tree.complexity),
maxnet = maxnet(p=cv_train[,y_name], data = cv_train[,x_name]),
#gausspr = update(model, data=cv_train))
gausspr = kernlab::gausspr(species~., data = cv_train[,c(x_name, y_name)]), kernel = "rbfdot")
# We make predictions for k-fold:
if (class(model)[1]=='gbm') {
cross_val_preds[which(ks==i),2] <-
predict.gbm(modtmp, cv_test[, x_name], n.trees=model$gbm.call$best.trees, type="response")
} else {
cross_val_preds[which(ks==i),2] <- make.preds(modtmp, cv_test[, x_name])
}
}
return(cross_val_preds[,2])
#return(cross_val_preds)
}
# MODEL PERFORMANCE MEASURES
calc.eval <- function(dat, colname_species, preds, thresh_method='MaxSens+Spec'){
require(PresenceAbsence)
require(dismo)
# Helper functions.
## True Skill Statistic:
TSS = function(cmx){
PresenceAbsence::sensitivity(cmx, st.dev=F) +
PresenceAbsence::specificity(cmx, st.dev=F) - 1
}
## Explained deviance - the function calc.deviance() is taken from the dismo package:
d.square <- function(obs, pred, family='binomial'){
pred <- ifelse(pred<.00001,.00001,ifelse(pred>.9999,.9999,pred))
null_pred <- rep(mean(obs), length(obs))
1 - (calc.deviance(obs, pred, family=family) /
calc.deviance(obs, null_pred, family=family))
}
# Prepare data set to optimise threshold for binarising:
thresh_dat <- data.frame(ID=seq_len(nrow(dat)),
obs = dat[, colname_species],
pred = preds)
# Find optimal threshold using the package PresenceAbsence
thresh <- optimal.thresholds(DATA= thresh_dat)
# Prepare confusion matrix
cmx_maxSSS <- cmx(DATA= thresh_dat, threshold=thresh[thresh$Method==thresh_method,2])
# Generate output data frame with performance statistics and optimal threshold:
data.frame(AUC = PresenceAbsence::auc(thresh_dat, st.dev=F),
TSS = TSS(cmx_maxSSS),
Sens = PresenceAbsence::sensitivity(cmx_maxSSS, st.dev=F),
Spec = PresenceAbsence::specificity(cmx_maxSSS, st.dev=F),
PCC = PresenceAbsence::pcc(cmx_maxSSS, st.dev=F),
D2 = d.square(thresh_dat$obs, thresh_dat$pred),
thresh = thresh[thresh$Method==thresh_method,2])
}
# ----------------------------------------------------------------------------------------------------
# PREDICTOR VARIABLES
# ----------------------------------------------------------------------------------------------------
# Mask
mask <- raster("Data/Mask/EUROPE_MASK_10km.tif")
# CHELSA Bioclim
l_bioclim <- list.files("Data/Predictors/CHELSA_Bioclim", pattern = ".tif$", full.names = T)
bioclim <- raster::stack(l_bioclim)
names(bioclim) <- paste0("bio", 1:dim(bioclim)[3])
# LC fractions
l_lcf <- list.files("Data/Predictors/LC_Fractions", pattern = ".tif$", full.names = T)
lcf <- raster::stack(l_lcf)
names(lcf) <- c("f_artifical", "f_bare", "f_cropland", "f_highveg", "f_lowveg")
# DEM
dem <- raster("Data/Predictors/DEM/GTOPO30_10km.tif_EUROPE.tif")
names(dem) <- "dem"
# Landsat Spectral Temporal Metrics
l_stm <- list.files("Data/Predictors/Landsat_STMs", pattern = ".tif$", full.names = T)
stm <- raster::stack(l_stm)
names(stm) <- apply(expand.grid(c("tcb", "tcg", "tcw"), c("sos", "pos", "eos")), 1, paste, collapse=".")
brick_preds <- brick(list(bioclim, lcf, dem, stm))
brick_preds <- raster::mask(brick_preds, mask, maskvalue = 0)
# standardise data (z-transformation)
brick_preds_val <- getValues(brick_preds)
brick_preds_val <- scale(brick_preds_val)
brick_preds <- setValues(brick_preds, brick_preds_val)
help(scale)
brick_preds_val
# ----------------------------------------------------------------------------------------------------
# SPECIES DATA
# ----------------------------------------------------------------------------------------------------
r_pre <- raster(paste0("Data/GBIF/", species, "_europe_1990-2020_presence_thinned.tif"))
r_abs <- raster(paste0("Data/GBIF/", species, "_europe_1990-2020_absence_thinned.tif"))
# with buffer
buffer <- raster(paste0("Data/GBIF/", species, "_europe_1990-2020_presence_thinned_buffer_50km.tif"))
r_abs <- mask(r_abs, buffer, maskvalue=1)
r_pre[r_pre == 1] <- 2
pre_abs <- brick(c(r_pre, r_abs))
pre_abs <- as.matrix(pre_abs)
pre_abs <- apply(pre_abs, 1, FUN=sum, na.rm = T)
pre_abs[pre_abs == 0] <- NA
pre_abs <- pre_abs-1
df <- as.data.frame(brick_preds, xy = TRUE)
df[, "species"] <- pre_abs
#df <- cbind(df_preds, eval(species) = pre_abs)
df <- drop_na(df)
X_names <- names(df)[4:length(df)-1]
y_name <- "species"
# variable correlations
var_names <- append(X_names, y_name)
cor_mat <- cor(df[var_names], method='spearman')
corrplot(cor_mat, tl.srt=45, tl.col="black")
var_sel <- mecofun::select07_cv(X = df[, X_names], y = df[, y_name], kfold = 5, threshold = 0.5)
pred_sel <- var_sel$pred_sel
print(pred_sel)
cor_mat <- cor(df[append(pred_sel, y_name)], method='spearman')
corrplot(cor_mat, tl.srt=45, tl.col="black")
# Check how many data points are needed given the number of predictors
print(dim(df[df$species == 1,]))  # returns 867
print(length(pred_sel) * 10 * 2)  # returns 260
# weighting presence-absence data
n_pre <- dim(df[df$species == 1,])[1]
n_abs <- 5000
abs_weights <- n_pre / n_abs
df_sub <- sample_n(df[df$species == 0,], n_abs)
df_sub <- rbind(df_sub, df[df$species == 1,])
df_sub$weight <- ifelse(df_sub$species == 1, 1, abs_weights)  # abs_weight or 1 if equally
n_pre <- dim(df[df$species == 1,])[1]
n_abs <- dim(df[df$species == 1,])[1]
df_sub_ml <- sample_n(df[df$species == 0,], n_abs)
df_sub_ml <- rbind(df_sub_ml, df[df$species == 1,])
# (8) Gaussian Process Classification (GPC)
# option 1
library(GRaF)
m_gpc1 <- GRaF::graf(y = as.factor(df_sub_ml$species), x = df_sub_ml[,pred_sel])
m_gpc1 <- GRaF::graf(y = df_sub_ml$species, x = df_sub_ml[,pred_sel])
m_gpc1
m_gpc1$MAP
m_gpc1$K
m_gpc1$ls
m_gpc1$a
help(graf)
plot(m_gpc1)
x = df_sub_ml[,pred_sel]
x
x$f_artifical
dens(x$f_artifical)
plot(density(x$f_artifical))
plot(density(x$f_highveg))
plot(density(x$f_lowveg))
plot(m_gpc1[1])
plot(m_gpc1)
DIC(m_gpc1)
library(dismo)
d.square <- function(obs, pred, family='binomial'){
pred <- ifelse(pred<.00001,.00001,ifelse(pred>.9999,.9999,pred))
null_pred <- rep(mean(obs), length(obs))
1 - (calc.deviance(obs, pred, family=family) /
calc.deviance(obs, null_pred, family=family))
}
help("calc.deviance")
m_gpc1 <- GRaF::graf(y = df_sub_ml$species, x = df_sub_ml[,pred_sel])
help(graf)
par(mfrow = c(3, 4))
plot(m_gpc1)
par(mfrow = c(3, 4))
plot(m_gpc1)
m_gpc1
test <- predict(m_gpc1, brick_preds[[pred_sel]])
test
plot(test[[1]])
par(mfrow = c(1, 1))
plot(test[[1]])
beginCluster(n=8)
test <- predict(m_gpc1, brick_preds[[pred_sel]])
endCluster()
beginCluster(n=8)
test <- raster::predict(m_gpc1, brick_preds[[pred_sel]], progress = "text")
endCluster()
beginCluster(n=8)
test <- raster::predict(brick_preds[[pred_sel]], m_gpc1, progress = "text")
endCluster()
beginCluster(8)
test <- clusterR(brick_preds[[pred_sel]], predict, model=m_gpc1, progress="text")
#test <- raster::predict(brick_preds[[pred_sel]], m_gpc1, progress = "text")
endCluster()
rm(test)
beginCluster(8)
test <- clusterR(brick_preds[[pred_sel]], predict, args=list(model=m_gpc1, progress="text"))
#test <- raster::predict(brick_preds[[pred_sel]], m_gpc1, progress = "text")
endCluster()
test
beginCluster(4)
test <- clusterR(brick_preds[[pred_sel]], predict, args=list(model=m_gpc1, progress="text"))
#test <- raster::predict(brick_preds[[pred_sel]], m_gpc1, progress = "text")
endCluster()
beginCluster(4)
test <- clusterR(brick_preds[[pred_sel]], raster::predict, args=list(model=m_gpc1, progress="text"))
#test <- raster::predict(brick_preds[[pred_sel]], m_gpc1, progress = "text")
endCluster()
plot(test[[1]])
test
beginCluster(4)
test <- clusterR(brick_preds[[pred_sel]], raster::predict, args=list(model=m_gpc1))
#test <- raster::predict(brick_preds[[pred_sel]], m_gpc1, progress = "text")
endCluster()
beginCluster(15)
test <- clusterR(brick_preds[[pred_sel]], raster::predict, args=list(model=m_gpc1))
endCluster()
test
plot(test)
plot(test, col="jet")
plot(test, color.palette = jet.colors)
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan",
+                      "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan",
"#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))
plot(test, )
plot(test, col=jet.colors)
plot(test, color=jet.colors)
help(plot)
plot(test, col=jet.colors(10))
plot(test, col=jet.colors(100))
help(graf)
m_gpc1 <- GRaF::graf(y = df_sub_ml$species, x = df_sub_ml[,pred_sel], opt.l = TRUE, method = "Laplace", verbose = TRUE)
gpc_pred_prob <- raster::predict(m_gpc1, brick_preds[[pred_sel]], type="response", progress = "text")  # probability scale predictions
gpc_pred_lat <- raster::predict(m_gpc1, brick_preds[[pred_sel]], type="latent", CI = 'std', progress = "text")  # mean & std on Gaussian scale
#beginCluster(4)
#test <- clusterR(brick_preds[[pred_sel]], raster::predict, args=list(model=m_gpc1))
#endCluster()
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan",
"#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))
plot(gpc_pred_prob[[1]], col=jet.colors(100))
plot(gpc_pred_lat[[1]], col=jet.colors(100))
gpc_pred_lat
plot(gpc_pred_lat[[2]], col=jet.colors(100))  # 'uncertainty', i.e. std of the multivariate Gaussian around the mean prediction
plot(gpc_pred_prob[[1]], col=jet.colors(100))
print(m_gpc1)
plot(gpc_pred_lat[[2]], col=jet.colors(100))  # 'uncertainty', i.e. std of the multivariate Gaussian around the mean prediction
plot(gpc_pred_lat[[2]]^2, col=jet.colors(100))  # 'uncertainty', i.e. std of the multivariate Gaussian around the mean prediction
gpc_pred_lat[[2]]^2
gpc_pred_lat[[2]]
gpc_pred_lat[[2]]^2
plot(gpc_pred_lat[[2]], col=jet.colors(100))  # 'uncertainty', i.e. std of the multivariate Gaussian around the mean prediction
plot(gpc_pred_lat[[2]]^2, col=jet.colors(100))  # 'uncertainty', i.e. std of the multivariate Gaussian around the mean prediction
#m_gpc1 <- GRaF::graf(y = df_sub_ml$species, x = df_sub_ml[,pred_sel], opt.l = TRUE, method = "Laplace", verbose = TRUE)
m_gpc1 <- GRaF::graf(y = df_sub_ml$species, x = df_sub_ml[,pred_sel], method = "Laplace", verbose = TRUE)
gpc_pred_prob <- raster::predict(m_gpc1, brick_preds[[pred_sel]], type="response", progress = "text")  # probability scale predictions
plot(gpc_pred_prob[[1]], col=jet.colors(100))
df_sub
#m_gpc1 <- GRaF::graf(y = df_sub_ml$species, x = df_sub_ml[,pred_sel], opt.l = TRUE, method = "Laplace", verbose = TRUE)
#m_gpc1 <- GRaF::graf(y = df_sub_ml$species, x = df_sub_ml[,pred_sel], method = "Laplace", verbose = TRUE)
m_gpc1 <- GRaF::graf(y = df_sub$species, x = df_sub[,pred_sel], method = "Laplace", verbose = TRUE)
gpc_pred_prob <- raster::predict(m_gpc1, brick_preds[[pred_sel]], type="response", progress = "text")  # probability scale predictions
plot(gpc_pred_prob[[1]], col=jet.colors(100))
plot(gpc_pred_prob[[1]], col=jet.colors(100))
help(graf)
#m_gpc1 <- GRaF::graf(y = df_sub_ml$species, x = df_sub_ml[,pred_sel], opt.l = TRUE, method = "Laplace", verbose = TRUE)
#m_gpc1 <- GRaF::graf(y = df_sub_ml$species, x = df_sub_ml[,pred_sel], method = "Laplace", verbose = TRUE)
m_gpc1 <- GRaF::graf(y = df_sub$species, x = df_sub[,pred_sel], method = "Laplace", weights = df_sub$weight, verbose = TRUE)
gpc_pred_prob <- raster::predict(m_gpc1, brick_preds[[pred_sel]], type="response", progress = "text")  # probability scale predictions
